{
    "script": "main",
    "cartesian_hyperparams": {
      "batch_size": [32],
      "dataset_name": ["chemical_reactions"],
      "dataset_file_path": ["/Mounts/rbg-storage1/datasets/ChemicalReactions/chem_reactions_dataset.json"],
      "randomize_order_in_reaction": [true],
      "use_random_smiles_representation": [true],
      "lightning_name": ["base"],
      "model_name": ["reaction_mlm"],
      "num_classes": [581],
      "vocab_path": ["/Mounts/rbg-storage1/datasets/ChemicalReactions/vocab.txt"],
      "max_seq_len": [4096],
      "do_masked_language_model": [true],
      "mlm_probability": [0.2],
      "callback_names": ["lr_monitor checkpointer"],
      "max_epochs": [100],
      "lr_decay": [0.1],
      "lr": [1e-5],
      "weight_decay": [0.01],
      "loss_names": ["cross_entropy"],
      "precomputed_loss": [true],
      "metric_names": ["classification"],
      "checkpoint_save_last": [false],
      "monitor": ["val_accuracy"],
      "num_workers": [3],
      "optimizer_name": ["adam"],
      "patience": [5],
      "train": [true],
      "dev": [true],
      "test": [true],
      "num_sanity_val_steps": [0],
      "val_check_interval": [1.0],
      "gpus": [8],
      "ignore_warnings": [false],
      "dropout": [0],
      "checkpoint_dir": ["/Mounts/rbg-storage1/snapshots/metabolomics"],
      "logger_name": ["wandb"],
      "workspace": ["peteranditamar"],
      "project_name": ["metabolomics"],
      "logger_tags": ["mlm"]
    },
    "available_gpus": ["0,1,2,3,4,5,6,7"]
  }
  
